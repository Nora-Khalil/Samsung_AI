{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8409fd32-f38d-4e84-b446-98e110606620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "data=load_breast_cancer()\n",
    "#pd.DataFrame(data['data'])\n",
    "#pd.DataFrame(data['target'])\n",
    "\n",
    "#NK: it seems like data['data'] is raw data, data['target'] is actual value (cancerous v. noncancerous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59bde605-d62b-4cfe-a436-90a24b73647f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_test_split in module sklearn.model_selection._split:\n",
      "\n",
      "train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)\n",
      "    Split arrays or matrices into random train and test subsets\n",
      "    \n",
      "    Quick utility that wraps input validation and\n",
      "    ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data in a\n",
      "    oneliner.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "    \n",
      "    test_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. If ``train_size`` is also None, it will\n",
      "        be set to 0.25.\n",
      "    \n",
      "    train_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, default=None\n",
      "        Controls the shuffling applied to the data before applying the split.\n",
      "        Pass an int for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "    \n",
      "    \n",
      "    shuffle : bool, default=True\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "    \n",
      "    stratify : array-like, default=None\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "        Read more in the :ref:`User Guide <stratification>`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "    \n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "    \n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "    \n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(data.DESCR) #prints description of dataset \n",
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da98ff65-7831-4906-9d8b-ba1e8bc3ef74",
   "metadata": {},
   "source": [
    "Supervised Learning with Decision Trees: Unstandardized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "846f25b8-cc0b-42c3-bb15-3d2258f4bd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NK: split the data into a train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.25, random_state=0)\n",
    "#NK: instancing the estimator. \"criterion\" is a hyperparameter setting\n",
    "model = DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "#NK: use the fit method with instance estimator for training. Send the training data and label data together as an\n",
    "#argument to supervised learning algorithm. \n",
    "model.fit(X_train,y_train) #sup\n",
    "\n",
    "#NK: the instance estimator that HAS COMPLETED training with fitting can be applied with the predict method. \n",
    "# \"Predict\" converts the estimated results of the model regarding the entered data. \n",
    "y_pred=model.predict(X_test) #is an estimated value, so the actual values for X_test may vary. Measure the accuracy by comparing the two values.\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0070242e-eb8d-4d37-bf78-50ffc2a1589f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size y_test: 143\n",
      "unmatch size: 7\n",
      "matched size: 136\n",
      "unmatch rate: 0.04895104895104895\n",
      "match rate: 0.951048951048951\n"
     ]
    }
   ],
   "source": [
    "#this is comparing the predicted test data with what the actual y values should be \n",
    "pred_2d = y_pred.reshape(len(y_pred),1)\n",
    "df1=pd.DataFrame(pred_2d) \n",
    "y_test_2d=y_test.reshape(len(y_test),1)\n",
    "df1=pd.DataFrame(pred_2d)\n",
    "df2=pd.DataFrame(y_test_2d) \n",
    "df_concat=pd.concat([df1,df2],axis=1) \n",
    "df_concat.columns=['pred','real']\n",
    "\n",
    "df_size=df_concat[df_concat['pred']!=df_concat['real']]\n",
    "#df_size shows results where the predicted value and actual value differ\n",
    "\n",
    "mf_size=df_concat[df_concat['pred']==df_concat['real']]\n",
    "#mf_size shows results where the predicted value and actual value were the same. \n",
    "\n",
    "y_len = len(y_test) #test size \n",
    "u_size=len(df_size) #unmatched\n",
    "m_size=len(mf_size) #matched \n",
    "print(\"size y_test:\",y_len)\n",
    "print(\"unmatch size:\",u_size)\n",
    "print(\"matched size:\",m_size)\n",
    "print(\"unmatch rate:\",u_size/y_len)\n",
    "print(\"match rate:\",m_size/y_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61359f1d-e914-4653-87ef-a94d7db2e613",
   "metadata": {},
   "source": [
    "Supervised Learning with Decision Trees: Standardized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "911f8a82-c824-408c-93c6-56348d985376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "scaler=StandardScaler() #class for standardization. Standardization can increase the data accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "935ec9b8-6699-4a41-bcfb-3956915d9075",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=load_breast_cancer()\n",
    "#pd.DataFrame(data['data'])\n",
    "#pd.DataFrame(data['target'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3302f509-b21c-4407-a45f-08ebf8776a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEFORE PRE_PROCESSING. differences among column values are huge before standardization \n",
    "df_scale_previous=pd.DataFrame(data['data'])\n",
    "\n",
    "#PRE_PROCESSING STARTS HERE\n",
    "#.fit computes the mean and std to be used for later scaling\n",
    "scaler.fit(X_train)\n",
    "\n",
    "#.transform performs standardization by centering and scaling. \n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "df_scale_after=pd.DataFrame(X_train)\n",
    "\n",
    "#after standardization, the column values do not significantly deviate from 0. \n",
    "#Better performance would be possible compared to before standardization. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e9f2c6-54bc-49de-b95b-d1920dbb2231",
   "metadata": {},
   "source": [
    "Supervised Learning with Decision Trees: Standardized Data (fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3695301-b052-4716-af9c-bc4a93c5768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "scaler=StandardScaler() #class for standardization. Standardization can increase the data accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e1800a8-c51a-4fd4-a2e9-eb5a080c6b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=load_breast_cancer()\n",
    "#pd.DataFrame(data['data'])\n",
    "#pd.DataFrame(data['target'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b53ec4f-dd63-456c-8e0e-28724ab5e2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale X_train & X_test\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "# removes the mean and scales to unit variance. Fit and Transform is combined as fit_transform. \n",
    "\n",
    "\n",
    "# We ignore the shape of the distribution and just transform the data to center it by removing the mean value of each feature. \n",
    "# We then scale it by dividing non-constant features by their standard deviation. \n",
    "\n",
    "# Scaled data using StandardScaler() has zero mean and unit variance. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "670b5c5e-94a9-46c5-a7ac-da34f59879ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size y_test: 143\n",
      "unmatch size: 14\n",
      "matched size: 129\n",
      "unmatch rate: 0.0979020979020979\n",
      "match rate: 0.9020979020979021\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(criterion='entropy')\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "pred_2d = y_pred.reshape(len(y_pred),1)\n",
    "df1=pd.DataFrame(pred_2d) \n",
    "y_test_2d=y_test.reshape(len(y_test),1)\n",
    "df1=pd.DataFrame(pred_2d)\n",
    "df2=pd.DataFrame(y_test_2d) \n",
    "df_concat=pd.concat([df1,df2],axis=1) \n",
    "df_concat.columns=['pred','real']\n",
    "df_size=df_concat[df_concat['pred']!=df_concat['real']]\n",
    "mf_size=df_concat[df_concat['pred']==df_concat['real']]\n",
    "y_len = len(y_test)\n",
    "u_size=len(df_size)\n",
    "m_size=len(mf_size)\n",
    "print(\"size y_test:\",y_len)\n",
    "print(\"unmatch size:\",u_size)\n",
    "print(\"matched size:\",m_size)\n",
    "print(\"unmatch rate:\",u_size/y_len)\n",
    "print(\"match rate:\",m_size/y_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15858a66-3ade-4efc-a865-4de9b38f2e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "scaler=StandardScaler() \n",
    "\n",
    "data=load_iris()\n",
    "#pd.DataFrame(data['data'])\n",
    "#pd.DataFrame(data['target'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, random_state=10)\n",
    "# scale X_train & X_test\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "model = DecisionTreeClassifier(criterion='entropy')\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "pred_2d = y_pred.reshape(len(y_pred),1)\n",
    "df1=pd.DataFrame(pred_2d) \n",
    "y_test_2d=y_test.reshape(len(y_test),1)\n",
    "df1=pd.DataFrame(pred_2d)\n",
    "df2=pd.DataFrame(y_test_2d) \n",
    "df_concat=pd.concat([df1,df2],axis=1) \n",
    "df_concat.columns=['pred','real']\n",
    "df_size=df_concat[df_concat['pred']!=df_concat['real']]\n",
    "mf_size=df_concat[df_concat['pred']==df_concat['real']]\n",
    "y_len = len(y_test)\n",
    "u_size=len(df_size)\n",
    "m_size=len(mf_size)\n",
    "print(\"size y_test:\",y_len)\n",
    "print(\"unmatch size:\",u_size)\n",
    "print(\"matched size:\",m_size)\n",
    "print(\"unmatch rate:\",u_size/y_len)\n",
    "print(\"match rate:\",m_size/y_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27dfe68-0d4e-4313-bdb2-fb700bfa887f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
